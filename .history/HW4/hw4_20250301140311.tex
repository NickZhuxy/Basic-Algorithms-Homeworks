\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{tcolorbox}
\usepackage{enumerate}
\usepackage{tikz}
\usepackage{indentfirst}

\usepackage{algorithmic}

\newcommand{\zo}{\{0,1\}}
\usetikzlibrary{shapes.geometric,arrows,fit,matrix,positioning}
\tikzset
{
    treenode/.style = {circle, draw=black, align=center, 
                          minimum size=1cm, anchor=center}
}

\newcommand{\mfive}{\text{Median5}}

\begin{document}

    \setlength{\headheight}{26pt}
    \pagestyle{fancy}
    \fancyhead[C]{\textbf{Basic Algorithms (Section 5)}\\Spring 2025}
    \fancyhead[R]{HW4 (Due 2/27	 23:59)\\ Instructor: Jiaxin Guan}
    \fancyfoot[C]{}
    \fancyfoot[R]{\thepage}
    \renewcommand{\headrulewidth}{0.4pt}
    \renewcommand{\footrulewidth}{0.4pt}
    %%%% EDIT THIS PART 
    
    %Put your name and Net ID here
	\fancyhead[L]{Name: Nick Zhu  \\ Net ID: xz4687}
    %Write your collaborators' names here
    \fancyfoot[L]{Discussion Partners:}
    %%%%%
    
    \begin{itemize}
    \item \textbf{Due Date:} \textbf{Thursday, February 27th, 23:59}
    \item \textbf{Late submission} will be accepted \textbf{without} penalty until \textbf{Saturday, March 1st, 23:59}.
    \item \textbf{No submissions will be accepted after March 1st, 23:59.}
    \end{itemize}

     %Problem 1
    \begin{tcolorbox}[title={Problem 1 (Selection Algorithm, 35 pts)}] \setlength\parindent{1em}
        Recall the deterministic selection algorithm for the median that we saw in class (Lecture $8$ and $9$, but see lecture note $7$). In there, to compute the "approx-median" (element within the middle $40\%$), we break the elements into small sets of size $5$, compute the median for each small set, and then output the median of these $n/5$ medians as the "approx-median".
        \begin{enumerate}[(a)]
           \item If instead of breaking into small sets of size $5$, we break into small sets of size $3$:
           \begin{enumerate}[i.]
               \item Will the "approx-median" we get in this way still be in the middle $40\%$? Find $k$, such that the "approx-median" we get will be guaranteed to be in the middle $k$ portion. For example, if it is guaranteed to be in the middle $40\%$, then $k=\frac{2}{5}$. Justify your answer, and $k$ should be as tight (small) as possible.
               \item Will the deterministic selection algorithm be still correct in this case? Briefly justify your answer.
               \item Give a recurrence relation for the runtime of this version of the deterministic selection algorithm. Can we still argue that it is in linear time? Justify your answer.
           \end{enumerate}
           \item If instead of breaking into small sets of size $5$, we break into small sets of size $7$:
           \begin{enumerate}[i.]
               \item Will the "approx-median" we get in this way still be in the middle $40\%$? Find $k$, such that the "approx-median" we get will be guaranteed to be in the middle $k$ portion. Justify your answer, and $k$ should be as tight (small) as possible.
               \item Will the deterministic selection algorithm be still correct in this case? Briefly justify your answer.
               \item Give a recurrence relation for the runtime of this version of the deterministic selection algorithm. Can we still argue that it is in linear time? Justify your answer.
           \end{enumerate}
           \item Any advantages of using 5 as opposed to some other number? In other words, was our choice of $5$ arbitrary? (Just expecting a short, one-line answer here)
       \end{enumerate}
    \end{tcolorbox}
    %Write your solution here!
    \section*{Solution}

    We analyze two variants of the deterministic selection (median‐of‐medians) algorithm where we partition the input into groups of size 3 and 7, respectively, instead of the standard 5. For each variant we answer (i), (ii), and (iii).
    
    \bigskip
    
    \subsection*{(a) Using Groups of Size 3}
    
    \textbf{(i) Approximate Median Location.}  
    When we divide the \(n\) elements into groups of 3, there are about \(\frac{n}{3}\) groups. In each group the median is the second smallest element. When we take the median of these medians (call it \(m\)), at least half of the group medians are \(\le m\) and at least half are \(\ge m\).  
    \[
    \text{Number of groups with median } \le m \ge \frac{n}{6}.
    \]
    In any group with median \(\le m\), the smallest and the median (i.e. 2 elements) are \(\le m\). Thus, there are at least 
    \[
    2\cdot\frac{n}{6} = \frac{n}{3}
    \]
    elements that are \(\le m\). A symmetric argument shows that at least \(\frac{n}{3}\) elements are \(\ge m\). Therefore, the approximate median \(m\) is guaranteed to lie between the \(\frac{n}{3}\)th and the \(\frac{2n}{3}\)th order statistics – that is, it lies in the middle \(\frac{1}{3}\) (or \(33.3\%\)) portion of the array. (In the standard case with groups of 5, one can show that the pivot lies in the middle \(40\%\), i.e. \(k=\frac{2}{5}\). Here, we have \(k=\frac{1}{3}\).)
    
    \medskip
    
    \textbf{(ii) Correctness.}  
    The algorithm is still correct in that the pivot \(m\) is a valid approximate median. However, because the pivot is only guaranteed to lie in the middle \(\frac{1}{3}\) portion (rather than the middle \(40\%\) as with groups of 5), the amount of progress (i.e. the number of elements eliminated in each recursive step) is not as strong.
    
    \medskip
    
    \textbf{(iii) Running Time.}  
    Let \(T(n)\) be the worst-case time for selecting the \(i\)th order statistic from \(n\) elements. In the groups-of-3 variant:
    \begin{itemize}
        \item Forming the \(\frac{n}{3}\) groups and finding each group’s median takes \(O(n)\) time.
        \item Recursively computing the median-of-medians takes time \(T\bigl(\frac{n}{3}\bigr)\).
        \item A standard partition about the pivot takes \(O(n)\) time.
    \end{itemize}
    In the worst case, by the above analysis at least \(\frac{n}{3}\) elements are \(\le m\) and at least \(\frac{n}{3}\) are \(\ge m\). Thus, the larger partition has size at most
    \[
    n - \frac{n}{3} = \frac{2n}{3}.
    \]
    This yields the recurrence
    \[
    T(n) \le T\Bigl(\frac{n}{3}\Bigr) + T\Bigl(\frac{2n}{3}\Bigr) + O(n).
    \]
    A standard application of the recursion-tree method (or the Akra–Bazzi theorem) shows that this recurrence solves to
    \[
    T(n) = \Theta(n\log n).
    \]
    Thus, using groups of size 3 causes the algorithm to run in superlinear time in the worst case.
    
    \bigskip
    
    \subsection*{(b) Using Groups of Size 7}
    
    \textbf{(i) Approximate Median Location.}  
    When we divide the \(n\) elements into groups of 7, there are roughly \(\frac{n}{7}\) groups. In a group of 7 (when sorted) the median is the 4th smallest element. Now, consider the groups whose median is \(\le m\) (where \(m\) is the median-of-medians). There are at least \(\frac{n}{14}\) such groups. In any such group the smallest 4 elements are \(\le m\), so they contribute at least 4 elements each. Thus, there are at least
    \[
    4\cdot\frac{n}{14} = \frac{2n}{7}
    \]
    elements that are \(\le m\). A symmetric argument shows that at least \(\frac{2n}{7}\) elements are \(\ge m\). In other words, the pivot \(m\) is guaranteed to lie between the \(\frac{2n}{7}\)th and the \(\frac{5n}{7}\)th order statistics. Hence, \(m\) is in the middle
    \[
    \frac{5n}{7} - \frac{2n}{7} = \frac{3n}{7}
    \]
    portion of the array, so here we have \(k = \frac{3}{7}\) (approximately \(42.9\%\)).
    
    \medskip
    
    \textbf{(ii) Correctness.}  
    The algorithm remains correct because the pivot \(m\) is still a “good” approximate median – it is neither too low nor too high. In particular, at least \(\frac{2n}{7}\) elements are on each side of \(m\), ensuring that a constant fraction of the elements is eliminated in each recursive call.
    
    \medskip
    
    \textbf{(iii) Running Time.}  
    For groups of 7:
    \begin{itemize}
        \item Dividing into groups and computing each group’s median takes \(O(n)\) time.
        \item Recursively computing the median-of-medians takes time \(T\Bigl(\frac{n}{7}\Bigr)\).
        \item Partitioning around \(m\) takes \(O(n)\) time.
    \end{itemize}
    Since at least \(\frac{2n}{7}\) elements are \(\le m\) and at least \(\frac{2n}{7}\) are \(\ge m\), the worst-case size of the larger partition is at most
    \[
    n - \frac{2n}{7} = \frac{5n}{7}.
    \]
    Thus, the recurrence becomes
    \[
    T(n) \le T\Bigl(\frac{n}{7}\Bigr) + T\Bigl(\frac{5n}{7}\Bigr) + O(n).
    \]
    Here, note that
    \[
    \frac{1}{7} + \frac{5}{7} = \frac{6}{7} < 1.
    \]
    A recurrence of the form
    \[
    T(n) \le T(an) + T(bn) + O(n) \quad \text{with } a+b < 1
    \]
    resolves to \(T(n) = O(n)\). Therefore, the algorithm still runs in linear time when groups of size 7 are used.
    
    \bigskip
    
    \subsection*{(c) Advantages of Using 5}  
    The choice of 5 is not arbitrary: it is the smallest group size for which the “median-of-medians” selection algorithm guarantees a linear worst-case running time. Using groups of 3 yields only a \(\frac{1}{3}\) guarantee (and a recurrence that solves to \(\Theta(n\log n)\)), while groups of 7 (though still linear) introduce a larger constant in the running time. Thus, groups of 5 strike a good balance between having a pivot that is sufficiently “central” and keeping the overhead small.
    
    \bigskip
    
    \textbf{Summary of Answers:}
    \begin{enumerate}[(a)]
        \item \textbf{Groups of 3:}
        \begin{enumerate}[i.]
            \item The approximate median is guaranteed to lie in the middle \(\frac{1}{3}\) of the array (i.e. \(k=\frac{1}{3}\)).
            \item The algorithm remains correct (it will still return the true median), but the quality of the pivot is poor enough that the worst-case running time becomes \(\Theta(n\log n)\).
            \item The recurrence is 
            \[
            T(n) \le T\Bigl(\frac{n}{3}\Bigr) + T\Bigl(\frac{2n}{3}\Bigr) + O(n),
            \]
            which solves to \(\Theta(n\log n)\).
        \end{enumerate}
        \item \textbf{Groups of 7:}
        \begin{enumerate}[i.]
            \item The approximate median is guaranteed to lie in the middle \(\frac{3}{7}\) of the array (i.e. \(k=\frac{3}{7}\)).
            \item The algorithm remains correct and, because the recurrence 
            \[
            T(n) \le T\Bigl(\frac{n}{7}\Bigr) + T\Bigl(\frac{5n}{7}\Bigr) + O(n)
            \]
            satisfies \(\frac{1}{7}+\frac{5}{7} < 1\), it runs in linear time.
            \item Thus, the recurrence yields \(T(n)=O(n)\).
        \end{enumerate}
        \item \textbf{Choice of 5:}  
        Using groups of 5 is optimal because it is the smallest group size that guarantees a sufficiently central pivot to ensure a linear worst-case running time.
    \end{enumerate}


    \newpage
    %Problem 2
    \begin{tcolorbox}[title={Problem 2 (Finding Duplicates, 30 pts)}] \setlength\parindent{1em}
        Consider an array $A$ of $n$ elements where each element appears exactly twice in $A$, e.g. $A=[9, 7, 7, 1, 9, 1, 3, 5, 3, 5]$. For any two elements $A[i]$, $A[j]$ in the array, we may only compare the elements by testing equality, i.e., $A[i] \overset{?}{=} A[j]$. With this in mind,
        \begin{enumerate}[(a)]
            \item Give an algorithm that returns two indices in $A$ that have the same element using at most $n-2$ comparisons/equality tests. \emph{Note: there are multiple pairs of these indices, and only outputting one pair is sufficient. For example, $(1, 5), (2, 3), (4, 6), (7, 9), (8, 10)$ are all valid outputs of this algorithm on $A$.}
            \item Prove that your algorithm really needs $n-2$ comparisons in the worst case (i.e., there are inputs where it uses that many comparisons before terminating). Specifically, give an example of a worst-case input for $n = 10$. Note that this worst-case input only needs to work for \emph{your} algorithm in part (a), not \emph{any} algorithm.
        \end{enumerate}
    \end{tcolorbox}
    %Write your solution here!

    %Problem 3
    \begin{tcolorbox}[title={Problem 3 (Minimum and Maximum — Lower Bound, 35 pts)}]\setlength\parindent{1em}
    
    Suppose we have an array $A$ of $n$ distinct integers, and we want to find both the minimal and the maximal number. In Lecture $8$ (see lecture note $7$ though) we saw how to do this using $\frac{3n}{2} + O(1)$ comparisons, as opposed to the na\"{i}ve algorithm that uses $2(n-1)$ comparisons by making two separate passes to find the minimum and the maximum separately. Here, we will show that this is actually optimal in the comparison model by proving a lower bound of $\frac{3n}{2} - O(1)$ (and therefore the complexity of this problem is $\frac{3n}{2} + \Theta(1)$).

    \vspace{1em}
    
    For the lower bound, suppose there is an \emph{arbitrary} comparison-based algorithm that finds the minimum and maximum of $A$. Suppose we run this algorithm on some input and consider the situation after some step of the algorithm. Let us say that the element of the array has \emph{lost} comparison if it was compared with some other element and turned out to be smaller. Let us say that the element has \emph{won} comparison if it was compared to another element and it turned out to be larger. Without loss of generality, we will assume all elements are distinct, so the comparison result is either ``$<$" or ``$>$".

    \vspace{1em}
    
    Consider the following three parameters: 
    \begin{enumerate}
        \item Let $a$ be the number of elements of the array that have not been compared at all.
        \item Let $b$ be the number of elements that have both lost and won comparisons.
        \item Let $c$ be the number of elements that have either only lost or only won comparisons (at least $1$ comparison).
    \end{enumerate}
    
    \begin{enumerate}[(a)]
        \item What are the values of $a$, $b$, and $c$ at the beginning of the algorithm — before any comparisons are made?
        \item What are the values of $a$, $b$, and $c$ at the end of the algorithm — after the algorithm successfully found the largest and the smallest numbers?
        \item What relationship do $a$, $b$, and $c$ fulfill throughout the execution of the algorithm?
        \item Describe an adversarial strategy for answering comparison queries (consistent with some input) that makes the parameters $a$, $b$, and $c$ change as little as possible through the execution of the algorithm. Notice that you cannot control which elements are compared each time; you can only control the outcome. So you might want to produce the comparison outcome depending on the inputs. Deduce the $\frac{3n}{2} - O(1)$ lower bound in the comparison model. 
        
        (\textit{Hint: Consider you playing the role of the comparison oracle, and your friend playing the role of an algorithm. When your friend gives two elements for you to compare, you can produce an arbitrary answer, either ``$<$" or ``$>$" (you should imagine the case where there are no actual values associated with the elements, so you can answer arbitrarily). Think about which answer should you give, if you want your friend to take the longest time (i.e. to make the most number of queries) possible. You might want to break into cases where each of the elements has won/lost/both/neither.})
    \end{enumerate}
    \end{tcolorbox}
    %Write your solution here!
    \section*{Solution}
    \textbf{(a) Initial Values:} 
    
    Before any comparisons are made, every element has not been compared. Hence,
    \[
    a = n,\quad b = 0,\quad c = 0.
    \]
    
    \bigskip
    
    \textbf{(b) Final Values:}
    
    When the algorithm terminates, it must have correctly identified the minimum and the maximum. Note the following:
    \begin{itemize}
        \item The \emph{minimum} element must have lost at least one comparison but never won any.
        \item The \emph{maximum} element must have won at least one comparison but never lost any.
        \item Every other element must have lost at least once (so it cannot be the maximum) and won at least once (so it cannot be the minimum), meaning they have been \emph{eliminated} as candidates for either extreme.
    \end{itemize}
    Thus, at termination:
    \[
    a = 0,\quad c = 2,\quad b = n-2.
    \]
    
    \bigskip
    
    \textbf{(c) Invariant Relationship Throughout Execution:}
    
    At any point in the algorithm, we have the invariant
    \[
    a + b + c = n.
    \]
    Moreover, the algorithm must eventually eliminate all but two elements (the minimum and maximum), i.e., it must achieve \( b = n-2 \). An important observation is that in each comparison, the adversary can force the parameters to change so that at most one new element is moved into the eliminated group (increasing \( b \) by at most 1).
    
    \bigskip
    
    \textbf{(d) Adversarial Strategy and the Lower Bound:}
    
    The adversary’s goal is to answer comparisons in such a way that the parameters \( a \), \( b \), and \( c \) change as little (slow) as possible. The strategy is as follows:
    
    \begin{enumerate}
        \item \textbf{When both elements are in \( a \):}  
        The adversary can answer arbitrarily. This moves both elements from \( a \) to \( c \) (one becomes a “winner-only” candidate and the other a “loser-only” candidate). This requires one comparison, reducing \( a \) by 2 and increasing \( c \) by 2.
    
        \item \textbf{When one element is in \( a \) and the other in \( c \):}  
        The adversary answers so that the \( a \)-element acquires the same mark as the \( c \)-element. For instance, if the \( c \)-element is currently only a winner (a candidate for maximum), then declare that the \( a \)-element loses. This way, the \( c \)-element remains “half-decided” (staying in \( c \)) and the \( a \)-element joins \( c \) without forcing any element into \( b \).
    
        \item \textbf{When both elements are in \( c \):}  
        \begin{itemize}
            \item If both have the same mark (either both only winners or both only losers), the adversary can choose the outcome so that one element remains with only one mark. This avoids giving any element the missing mark and thus prevents moving an element into \( b \).
            \item If the two elements have opposite marks (one is a candidate for the maximum and the other for the minimum), then regardless of the answer, one of the elements will obtain the missing mark and will move into \( b \) (i.e., be eliminated). In this case, the adversary accepts that one elimination (an increase in \( b \)) is unavoidable.
        \end{itemize}
    \end{enumerate}
    
    Since initially all elements are in \( a \), we must first “open” them up by making about \( \frac{n}{2} \) comparisons (pairing the \( n \) elements to move them from \( a \) to \( c \)). Then, to eliminate the remaining \( n-2 \) elements (i.e., to have \( b = n-2 \) at termination), the algorithm must perform at least \( n-2 \) additional comparisons (each of which, in the worst case, eliminates at most one element). Therefore, the total number of comparisons is at least
    \[
    \frac{n}{2} + (n-2) = \frac{3n}{2} - 2.
    \]
    
    Thus, the lower bound on the number of comparisons is 
    \[
    \frac{3n}{2} - O(1).
    \]
    Since there exists an algorithm that finds the minimum and maximum in \(\frac{3n}{2} + O(1)\) comparisons, we conclude that the optimal complexity in the comparison model is
    \[
    \frac{3n}{2} + \Theta(1).
    \]
    \hfill\(\Box\)
\end{document}