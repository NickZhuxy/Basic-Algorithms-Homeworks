\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{tcolorbox}
\usepackage{enumerate}

\usepackage{algorithmic}

\newcommand{\zo}{\{0,1\}}


\begin{document}

    \setlength{\headheight}{26pt}
    \pagestyle{fancy}
    \fancyhead[C]{\textbf{Basic Algorithms (Section 5)}\\Spring 2025}
    \fancyhead[R]{HW1 (Due 2/6 23:59)\\ Instructor: Jiaxin Guan}
    \fancyfoot[C]{}
    \fancyfoot[R]{\thepage}
    \renewcommand{\headrulewidth}{0.4pt}
    \renewcommand{\footrulewidth}{0.4pt}
    
    %%%% EDIT THIS PART 
    %Put your name and Net ID here
	\fancyhead[L]{Name: Nick Zhu\\ Net ID: xz4687}
    %Write your collaborators' names here
    \fancyfoot[L]{Discussion Partners:}
    %%%%%
	
    
    %Problem 1
    \begin{tcolorbox}[title={Problem 1 (20 pts)}]
        Put the following functions in order in terms of $o$-notation:
        \begin{enumerate}
            \item $\sqrt{n}$
            \item $2^{\log_3 n}$
            \item $(\log n )^2$
            \item $3^n$
            \item $n^3$
            \item $8^{n/2}$
        \end{enumerate}
        Prove that your relation is correct for each adjacent pair. In particular, if your functions are ordered as $f_1,f_2,f_3,f_4,f_5,f_6$; then show that $f_1 \in o(f_2)$ and $f_2 \in o(f_3)$ and so on.
    \end{tcolorbox}
    \section*{Solution}
    \subsection*{Step 1. Ordering}
    The functions ordered from slowest to fastest growth are as follows:
    \[
    (\log n)^2, \quad \sqrt{n},\quad 2^{\log_3 n},\quad n^3,\quad 8^{n/2},\quad 3^n
    \]
    In $o$-notation, we write
    \[
    (\log n)^2 \in o(\sqrt{n}) \in o(2^{\log_3 n}) \in o(n^3) \in o(8^{n/2}) \in o(3^n).
    \]

    \subsection*{Step 2. Simplification}
    Before proving the relations, we simplify the functions to make the proofs easier. \\
    Using the identity
    \[
    a^{\log_b n} = n^{\log_b a}
    \]
    we have
    \[
    2^{\log_3 n} = n^{\log_3 2} \approx n^{0.63}
    \]
    Also,
    \[
    8^{n/2} = (8^{1/2})^n = (2\sqrt{2})^n
    \]

    \subsection*{Step 3. Proofs}
    \begin{itemize}
        \item {1. \((\log n)^2 \in o(\sqrt{n})\):}
        We need to show that
        \[
        \lim_{n\to\infty}\frac{(\log n)^2}{\sqrt{n}} = 0.
        \]
        Let \(n = 2^m\). Then,
        \[
        \log n = m \quad \text{and} \quad \sqrt{n} = 2^{m/2}.
        \]
        Thus,
        \[
        \frac{(\log n)^2}{\sqrt{n}} = \frac{m^2}{2^{m/2}},
        \]
        and as \(m\to\infty\), the exponential term in the denominator dominates the polynomial numerator, so the limit is 0.

        \item{2. \(\sqrt{n} \in o(2^{\log_3 n})\):}
        Since \(2^{\log_3 n} = n^{\log_3 2}\), we have
        \[
        \frac{\sqrt{n}}{2^{\log_3 n}} = \frac{n^{1/2}}{n^{\log_3 2}} = n^{\,1/2-\log_3 2}.
        \]
        Because \(1/2 - \log_3 2 < 0\),
        \[
        \lim_{n\to\infty} n^{\,1/2-\log_3 2} = 0.
        \]

        \item {3. \(2^{\log_3 n} \in o(n^3)\):}
        Since \(2^{\log_3 n} = n^{\log_3 2}\), we have
        \[
        \frac{2^{\log_3 n}}{n^3} = \frac{n^{\log_3 2}}{n^3} = n^{\,\log_3 2-3}.
        \]
        Because \(\log_3 2-3 < 0\),
        \[
        \lim_{n\to\infty} n^{\,\log_3 2-3} = 0.
        \]

        \item{4. \(n^3 \in o(8^{n/2})\):}
        Since the exponential function \(8^{n/2}\) grows much faster than the polynomial \(n^3\), we have
        \[
        \lim_{n\to\infty} \frac{n^3}{8^{n/2}} = 0,
        \]
        

        \item {5. \(8^{n/2} \in o(3^n)\):}
        We have
        \[
        \frac{8^{n/2}}{3^n} = \left(\frac{8^{1/2}}{3}\right)^n = \left(\frac{2\sqrt{2}}{3}\right)^n.
        \]
        Since \(\frac{2\sqrt{2}}{3} < 1\),
        \[
        \lim_{n\to\infty} \left(\frac{2\sqrt{2}}{3}\right)^n = 0.
        \]
    \end{itemize}
    %Write your solution here!

    \newpage
    %Problem 2
    \begin{tcolorbox}[title={Problem 2 (30 pts)}]
    Consider the function $f(n)= n\cdot ( n \mod 2) + \log n$.
    
    \begin{enumerate}[(a)]
        \item Show that $f(n) \in O(n)$ and $f(n) \in \Omega(\log n)$.
        \item Show that neither $f(n) \in \Theta(n)$ nor $f(n) \in \Theta(\log n)$.
        \item Suppose for some function $g(n)$, we have $f(n) \not \in O(g(n))$. Is it always true that $f(n)\in \omega(g(n))$? Justify your answer with either a proof or a counter-example.
    \end{enumerate}
    \end{tcolorbox}
    \section*{Solution}
    \textbf{(a)}

    \underline{\(f(n)\in O(n)\):}  
    For any \(n\ge 2\):
    \[
    \begin{array}{rcl}
    \text{If } n \text{ is even:} & f(n)= \log n &\le n,\\[1mm]
    \text{If } n \text{ is odd:} & f(n)= n+\log n &\le n+n = 2n.
    \end{array}
    \]
    Thus, \(f(n)\le 2n\) for all \(n\ge 2\). Choosing \(C=2\) and \(n_0=2\) gives \(f(n)\in O(n)\).

    \underline{\(f(n)\in \Omega(\log n)\):}  
    For all \(n\):
    \[
    \begin{array}{rcl}
    \text{If } n \text{ is even:} & f(n)= \log n,\\[1mm]
    \text{If } n \text{ is odd:} & f(n)= n+\log n &\ge \log n.
    \end{array}
    \]
    Thus, let \(c=1\) we have \(f(n)\ge \log n\) for all \(n\), so \(f(n)\in \Omega(\log n)\).
    \\
    \textbf{(b)}

    We prove by contradiction.
    
    Assum \(f(n)\in \Theta(n)\), then there exist constants \(c_1, c_2>0\) and \(n_0\) such that for all \(n\ge n_0\),
    \[
    c_1 n \le f(n) \le c_2 n.
    \]
    However, when \(n\) is even, \(f(n)=\log n\) and the inequality \(c_1 n \le \log n\) fails for large \(n\) (since \(\log n/n\to 0\)). Thus, we've reached a contradiction and \(f(n)\notin \Theta(n)\).

    Similarly, assume \(f(n)\in \Theta(\log n)\), then there exist constants \(c_1, c_2>0\) such that for all large \(n\),
    \[
    c_1 \log n \le f(n) \le c_2 \log n.
    \]
    But for odd \(n\), \(f(n)= n+\log n\) grows like \(n\), which is much larger than any constant multiple of \(\log n\). Thus, we've reached a contradiction and \(f(n)\notin \Theta(\log n)\).
    \\
    \textbf{(c)}

    It is not always true. We will show a counterexample.

    \underline{Counterexample:} Define
    \[
    g(n)=
    \begin{cases}
    n, & \text{if \(n\) is even},\\[1mm]
    \log n, & \text{if \(n\) is odd}.
    \end{cases}
    \]
    Then:
    \[
    \begin{array}{rcl}
    \text{If } n \text{ is even:} & f(n)=\log n,\quad g(n)=n,\quad \frac{f(n)}{g(n)}=\frac{\log n}{n}\to 0,\\[1mm]
    \text{If } n \text{ is odd:} & f(n)= n+\log n,\quad g(n)=\log n,\quad \frac{f(n)}{g(n)}\sim \frac{n}{\log n}\to \infty.
    \end{array}
    \]
    Thus, there is no constant \(C\) such that \(f(n)\le C\,g(n)\) for all large \(n\) (so \(f(n)\notin O(g(n))\)). However, \(f(n)\) also does not satisfy the definition of \(\omega(g(n))\) because for even \(n\), \lim_{n\to\infty} (f(n)/g(n)\) is arbitrarily small. 
    %Write your solution here!
    
    \newpage
    %Problem 3
    \begin{tcolorbox}[title={Problem 3 (20 pts)}]
    Let $f(n)$ and $g(n)$ be non-negative functions. \begin{enumerate}[(a)]
        \item Using the formal definition of $\Theta()$, prove that $\max(f(n),g(n))=\Theta(f(n)+g(n))$, where \[\max(a, b)=\begin{cases}
        a &\text{if } a\geq b\\
        b &\text{otherwise}
    \end{cases}.\]
        \item Can we also show that $\min(f(n),g(n))=\Theta(f(n)+g(n))$, where \[\min(a, b)=\begin{cases}
        a &\text{if } a\leq b\\
        b &\text{otherwise}
    \end{cases}?\] If yes, show how the proof from part (a) needs to be adapted. If no, provide a counter-example.
    \end{enumerate}
    
    \end{tcolorbox}
    %Write your solution here!
    
    \newpage
    %Problem 4
    \begin{tcolorbox}[title={Problem 4 (30 pts)}]
        You are given the coefficients $\alpha_0,\alpha_1,\ldots,\alpha_n$ of a polynomial
        \begin{align*}
            P(x) &= \sum_{k=0}^n \alpha_k x^k\\
            &= \alpha_0+\alpha_1x+\alpha_2x^2+\cdots+\alpha_nx^n,
        \end{align*}
        and you want to evaluate this polynomial for a given value of $x$. \emph{Horner's rule} says to evaluate the polynomial according to this parenthesization:
        \[
            P(x) = \alpha_0 + x \bigg(\alpha_1+x\Big(\alpha_2 +\cdots + x\left(\alpha_{n-1}+x\alpha_n\right)\cdots\Big)\bigg).
        \]
        
        The procedure \textsc{Horner} implements Horner's rule to evaluate $P(x)$, give the coefficients $\alpha_0,\alpha_1,\ldots,\alpha_n$ in an array $A[0:n]$ and the value of $x$.
        \bigskip
        
        \par\noindent\rule{\textwidth}{0.4pt}
        \smallskip        
        \textsc{Horner}$(A,n,x)$
        \begin{algorithmic}[1]
            \STATE $p\gets 0$
            \FOR{$i=n$ to $0$}
                \STATE $p \gets A[i]+x\cdot p$
            \ENDFOR
            \RETURN $p$
        \end{algorithmic}
        \vspace{-2mm}
        \par\noindent\rule{\textwidth}{0.4pt}
        
        {\it For this problem, assume that addition and multiplication can be done in constant time.}
        \begin{enumerate}[(a)]
            \item In terms of $\Theta$-notation, what is the running time of this procedure?
            \item Write pseudocode to implement the naive polynomial-evaluation algorithm that computes each term of the polynomial from scratch. What is the running time of this algorithm? How does it compare to \textsc{Horner}?
            \item Consider the following loop invariant for the prcedure \textsc{Horner}:\newline
            At the start of each iteration of the {\bf for} loop of lines 2-3,
            \[
            p = \sum_{k=0}^{n-(i+1)} A[k+i+1]\cdot x^k.
            \]
            Interpret a summation with no terms as equaling 0. Following the structure of the loop-invariant proof presented in class, use this loop invariant to show that, at termination, $p = \sum_{k=0}^n A[k] \cdot x^k$.
        \end{enumerate}
        
    \end{tcolorbox}
    
    
    %Your solution here
    
    %Comment out the next line if editing for your solutions
    \newpage \ 
    
    
    
\end{document}